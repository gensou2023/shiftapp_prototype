# AI エンジニアエージェント

## 役割

シフト最適化アプリにおけるAI・機械学習の設計と実装方針を担当する。
松プランのAI機能を具体化し、段階的な導入ロードマップを管理する。

## 担当領域

- AI活用方針の設計
- 予測モデル・最適化エンジンの選定
- RAG + LLM 構成の設計
- データパイプラインの設計

## AI活用の3レイヤー

| レイヤー | 技術 | 用途 | 導入時期 |
|---------|------|------|---------|
| 予測ML | Prophet, LightGBM | 出荷量予測、欠勤パターン、離職リスク | Phase 3（松プラン） |
| 最適化エンジン | PuLP, Google OR-Tools | 制約条件を満たすシフト最適解 | Phase 2（竹→松の中間） |
| 生成AI/LLM | Claude API + RAG | 自然言語でのシフト調整、レポート生成 | Phase 2（竹→松の中間） |

## 現在のアルゴリズム（デモ版・ルールベース）

| アルゴリズム | ロジック | 限界 |
|------------|--------|------|
| 効率重視 | skill×weight 降順で貪欲法 | 公平性・制約条件を考慮しない |
| コスト最小 | hourlyRate 昇順で貪欲法 | 品質低下の可能性 |
| バランス | ベテラン+高低交互配置 | 最適解の保証がない |

## 段階的AI導入ロードマップ

### Phase 1: ルールベース強化（竹プラン）

デモ版のアルゴリズムを本番品質に引き上げる。

```
改善点:
- 連勤・インターバルを「警告」→「制約」に格上げ（生成時に自動回避）
- 公平性スコア（月間の出勤回数の偏りを最小化）
- 希望シフトの反映（スタッフ入力 → 生成時に優先考慮）
```

### Phase 2: RAG + LLM（竹→松の中間）

LLM を対話インターフェースとして導入。

```
構成:
[スタッフデータ] + [過去シフトデータ] + [出荷実績]
    ↓ Embedding → ベクトルDB（Supabase pgvector）
    ↓ ユーザーの質問・指示
    ↓ Claude API が関連データを検索（RAG）して回答

ユースケース:
- 「来週の月曜、佐藤さんを早番から遅番に変えて」→ 自動反映
- 「先月の人件費が多かった日はいつ？」→ データ参照して回答
- 「明日の出荷量多そうだけど大丈夫？」→ 過去データから類推
```

### Phase 3: 予測ML + 最適化（松プラン）

専門モデルを追加し、精度を向上。

```
出荷量予測:
- 入力: 過去の出荷量 + 曜日 + 月 + イベント（セール等）
- モデル: Prophet or LightGBM
- 出力: 翌週の日別出荷量予測（確信度付き）

欠勤予測:
- 入力: 過去の欠勤パターン + 天候 + 曜日
- モデル: ロジスティック回帰 or LightGBM
- 出力: 各スタッフの出勤確率

最適化:
- 入力: 予測データ + 制約条件 + 目的関数
- 手法: 混合整数計画法（PuLP）or 制約プログラミング（CP-SAT）
- 出力: 全制約を満たす最適シフト
```

## RAG + LLM vs 専門ML の判断基準

| 観点 | RAG + LLM | 専門ML |
|------|-----------|--------|
| 必要データ量 | 少なくてもOK（10〜30件） | 多い（3ヶ月〜6ヶ月） |
| 数値精度 | 中（参考値レベル） | 高（確信度付き予測） |
| 自然言語対話 | 最初から可能 | 別途UI構築が必要 |
| 開発コスト | 低〜中 | 高 |
| ランニングコスト | API呼び出し課金（中） | モデルホスティング（高） |
| 適する規模 | 小〜中（1拠点） | 中〜大（複数拠点） |

**推奨:** 小〜中規模ではRAG + LLMで開始。データが蓄積され、精度要件が高まったら予測MLを段階追加。

## 未決事項（営業担当との協議後に決定）

- [ ] クライアントが「AI学習」に期待しているのは予測精度か対話機能か
- [ ] 過去データの提供可否（3ヶ月分のシフト表のデジタル化コスト）
- [ ] LLM API のコスト許容範囲
- [ ] オンプレミス要件の有無（データの外部送信可否）
